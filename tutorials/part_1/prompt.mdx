---
title: "Prompt Server：构造LLM的Prompt输入"
---

## 什么是 Prompt Tool

Prompt Tool 是 UltraRAG-MCP 中用于构建语言模型输入的组件。每个 Prompt Tool 由 @app.prompt 装饰定义，其主要职责是根据问题、检索段等输入，加载模板文件并生成标准化的 prompt message，可直接传递给 LLM 模型进行生成。

## 如何实现一个 Prompt Tool？

实现一个 Prompt Tool 通常包含以下三个步骤：

### 第一步：准备 Prompt 模板（Jinja2 格式）

请将你的 prompt 模板保存为 .jinja 结尾的文件，例如：

```jinja
Please answer the following question based on the given documents.
Think step by step.
Provide your final answer in the format \boxed{answer}.

Documents:
{{documents}}

Question: {{question}}
```

### 第二步：在 Prompt Server 中实现 Tool

调用我们提供的 load_prompt_template 方法加载模板，并在Prompt Server中实现一个工具函数（Tool）用于组装 prompt。

```python
@app.prompt(output="q_ls,ret_psg,template->prompt_ls")
def qa_rag_boxed(
    q_ls: List[str], ret_psg: List[str | Any], template: str | Path
) -> list[PromptMessage]:
    template: Template = load_prompt_template(template)
    ret = []
    for q, psg in zip(q_ls, ret_psg):
        passage_text = "\n".join(psg)
        p = template.render(question=q, documents=passage_text)
        ret.append(p)
    return ret
```

### 第三步：在 Pipeline 中使用该 Tool

1. 在 YAML 配置文件中注册 Prompt Server 并调用你实现的 Tool：

```yaml
# MCP Server
servers:
  generation: servers/generation
  prompt: servers/prompt

# MCP Client Pipeline
pipeline:
- prompt.qa_rag_boxed
- generation.generate
```

2. 构建后，修改运行时参数，指定你的模板文件路径：

```yaml
prompt:
  template: prompt/qa_rag_boxed.jinja
```