---
title: "Dataset and Format Description"
icon: "table"
---

## Existing Datasets

We have organized and preprocessed the most commonly used public evaluation datasets in the current RAG field, and will soon release a unified version on Hugging Face. Users can download and use them directly without additional processing.

The table below lists the supported task types and dataset statistics:

| Task Type           | Dataset Name          | Original Data Count                  | Leaderboard Sample Count             |
|---------------------|----------------------|--------------------------------------|--------------------------------------|
| qa                  | nq                   | 3,610                                | 1,000                                |
| qa                  | TriviaQA             | 11,313                               | 1,000                                |
| qa                  | popqa                | 14,267                               | 1,000                                |
| qa                  | AmbigQA              | 2,002                                | 1,000                                |
| qa                  | MarcoQA              | 101,093 ; 55,636 (filtered no-answer version) | 1,000 (filtered)         |
| qa                  | WebQuestions         | 2,032                                | 1,000                                |
| Multi-hop qa        | hotpotqa             | 7,405                                | 1,000                                |
| Multi-hop qa        | 2WikiMultiHopQA      | 12,576                               | 1,000                                |
| Multi-hop qa        | Musique              | 2,417                                | 1,000                                |
| Multi-hop qa        | bamboogle            | 125                                  | 125 (raw)                            |
| Multi-hop qa        | strategy-qa          | 2,290                                | 1,000                                |
| Multiple-choice     | ARC                  | 3,548 ; (choices: uppercase A–E, E for 1 sample) | 1,000                      |
| Multiple-choice     | mmlu                 | 14,042 ; (choices: uppercase A–D)    | 1,000                                |
| Long-form QA        | ASQA                 | 948                                  | 948 (raw)                            |
| fact-verification   | FEVER                | 13,332 ; (only support and refuse labels retained) | 1,000                 |
| dialogue            | WoW                  | 3,054                                | 1,000                                |
| slot-filling        | T-REx                | 5,000                                | 1,000                                |

Corpus statistics:

| Corpus Name | Document Count |
|-------------|---------------|
| wiki2018    | 21,015,324    |
| wiki2024    | Coming soon   |

## Data Format Description

We recommend users preprocess all test data into `.jsonl` format and follow the structure below to ensure compatibility with all UltraRAG modules:

Non-multiple-choice question data format:

```json
{
  "id": 0,  // integer ID
  "question": "xxxx",  // question text
  "golden_answers": ["xxx", "xxx"],  // list of standard answers, can contain multiple
  "metadata": { ... }  // other information fields, optional
}
```

Multiple-choice question data format:

```json
{
  "id": 0,
  "question": "xxxx",
  "golden_answers": ["A"],  // standard answer as option letter (e.g., A–D)
  "choices": ["xxx", "xxx", "xxx", "xxx"],  // list of option texts
  "metadata": { ... }
}
```

Corpus data format:

```json
{
  "id": "0",
  "contents": "xxxxx"  // text chunk after corpus splitting
}
```