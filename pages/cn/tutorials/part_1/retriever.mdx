---
title: "Retriever Server"
icon: "magnifying-glass"
---

## 作用

Retriever Server 是 UR-2.0 中的向量检索模块，集成了从文本嵌入、索引构建，到检索以及在线启动模型和模型部署多个功能。它支持端到端的知识检索流程，适用于大规模语料的快速向量化与高效召回。

## 参数说明

```yaml servers/retriever/parameter.yaml icon="/images/yaml.svg"
retriever_path: openbmb/MiniCPM-Embedding-Light
corpus_path: data/sample_hotpotqa_corpus_5.jsonl
embedding_path: embedding/embedding.npy
index_path: index/index.index

# infinity_emb config
infinity_kwargs:
  bettertransformer: false
  pooling_method: auto
  device: cuda
  batch_size: 1024

cuda_devices: "0,1"
query_instruction: "Query: "
faiss_use_gpu: True
top_k: 5
overwrite: false
retriever_url: http://localhost:8080
index_chunk_size: 50000

# OpenAI API configuration
use_openai: false
openai_model: "text-embedding-3-small"
api_base: ""
api_key: ""

# LanceDB configuration
lancedb_path: "lancedb/"
table_name: "vector_index"
filter_expr: null
```

- `retriever_path`：检索模型的名称/本地路径。
- `corpus_path`：语料文件路径（.jsonl），其中每行应包含 contents 字段，表示一段文档或段落。
- `embedding_path`：嵌入向量存储路径（.npy），用于索引构建或加载。如果当前没有，可以通过调用 retriever_embed tool 来编码获得，并保存到这个路径。
- `index_path`：索引保存路径（.index），用于加载已有索引或保存新索引。
- `infinity_kwargs`：infinity 库相关参数，需设定 pooling_method（支持 cls、mean、auto）及 batch_size 等
- `cuda_devices`：指定使用的 gpu 设备
- `query_instruction`：拼接到查询前的 prompt 前缀
- `faiss_use_gpu`：是否启用 GPU 加速的 FAISS 索引。若设为 False，FAISS 在 CPU 上运行。
- `top_k`：查询返回的文档数
- `overwrite`：是否允许覆盖已有的嵌入/索引文件。设置为 False 可避免覆盖已生成文件。
- `retriever_url`：用于设置部署 retriever 的地址和端口
- `index_chunk_size`：索引切片大小，防止 CPU 一次性加载全部数据导致 OOM

## 工具函数说明

- `retriever_init`：用于初始化加载检索器模型，加载语料数据，并加载已有索引（可选）
- `retriever_embed`：用于将先前加载的语料内容进行向量化编码，并将嵌入结果保存为 .npy 文件，供后续构建 FAISS 索引用。
- `retriever_index`：用于基于预生成的嵌入文件（.npy 格式）构建 FAISS 索引，并保存为 .index 文件，供向量检索使用。
- `retriever_search`：接收一组查询，将其编码为向量后，通过 FAISS 索引进行检索，返回每条查询对应的 top-k 相似文本内容。
- `retriever_deploy_service`：用于启动一个基于 Flask 的向量检索服务端，部署一个 /search 接口，支持通过 HTTP POST 请求执行语义检索。
- `retriever_deploy_search`：用于作为客户端访问远程 Flask 检索服务，将查询列表发送至指定服务地址，通过 HTTP POST 请求调用 /search 接口，并返回检索结果。
